# ğŸ§  DETR : End-to-End Object Detection with Transformers
> Nicolas Carion et al., ECCV 2020

---

## ğŸ¯ 1. Motivation â€” Object Detectionì˜ í•œê³„

- ê¸°ì¡´ detectorë“¤ì€ **object detectionì„ set prediction ë¬¸ì œ**ë¡œ ë³´ì§€ ëª»í•¨.
- ëŒ€ì‹  **ê°„ì ‘ì  ë°©ì‹(surrogate regression/classification)** ìœ¼ë¡œ ì ‘ê·¼.
  - **Regression** : anchorë‚˜ proposalì„ ê¸°ì¤€ìœ¼ë¡œ ë°•ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡
  - **Classification** : í•´ë‹¹ ìœ„ì¹˜ì— ì–´ë–¤ ê°ì²´ê°€ ìˆëŠ”ì§€ ë¶„ë¥˜
- â†’ ê²°êµ­ ì‚¬ëŒ ì†ìœ¼ë¡œ ì„¤ê³„í•œ ìš”ì†Œë“¤ì— ì˜ì¡´
  - **Anchor box**, **proposal**, **NMS(Non-Max Suppression)** ë“±

ğŸ“‰ **ë¬¸ì œì **
- ë§ì€ heuristic(ê²½í—˜ì  ê·œì¹™)ê³¼ hyperparameterì— ì˜ì¡´
- ê°ì²´ ê°„ **ì¤‘ë³µ ì˜ˆì¸¡**, **ìƒí˜¸ ê´€ê³„ ë¯¸ë°˜ì˜**

---

## ğŸš€ 2. Key Idea â€” Direct Set Prediction

> â€œObject detectionì„ **ì§ì ‘ì ì¸ ì§‘í•© ì˜ˆì¸¡ ë¬¸ì œ(set prediction problem)** ë¡œ ë³¸ë‹¤.â€

- **DETR**ì€ ëª¨ë“  ê°ì²´ë¥¼ **í•œ ë²ˆì— ë™ì‹œì—** ì˜ˆì¸¡í•¨ (End-to-End)
- í•µì‹¬ êµ¬ì„±ìš”ì†Œ  
  1. **Bipartite matching loss (Hungarian matching)**  
     â†’ ì˜ˆì¸¡ê³¼ ì •ë‹µì„ 1:1ë¡œ ëŒ€ì‘ì‹œì¼œ nms ë“±ì˜ í›„ì²˜ë¦¬ ì—†ì´ ì¤‘ë³µ ì œê±°ë¥¼ í•™ìŠµ ê³¼ì •ì—ì„œ í•´ê²° <br>
     â†’ permutation-invariant ë³´ì¥ (prediction ìˆœì„œê°€ ë°”ë€Œì–´ë„ ê²°ê³¼ê°€ ë™ì¼)  
  3. **Transformer encoder-decoder êµ¬ì¡°**  
     â†’ self-attentionì€ ì‹œí€€ìŠ¤ ë‚´ ëª¨ë“  ìš”ì†Œë“¤ì´ ì„œë¡œë¥¼ ë°”ë¼ë³´ë©°(attend) í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ê°ì²´ ê°„ì˜ ê´€ê³„(ê²¹ì¹¨, êµ¬ë¶„, ìƒí˜¸ë°°íƒ€ì„±)ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ê°€ëŠ¥ <br>
     â†’ ê°ì²´ ê°„ ê´€ê³„ë¥¼ ì „ì—­ì ìœ¼ë¡œ ëª¨ë¸ë§
  5. **Parallel decoding**  
     â†’ set ì˜ í¬ê¸°ê°€ ê°€ë³€ì ì´ê¸° ë•Œë¬¸ì— ê¸°ì¡´ì—ëŠ” autoregressiveë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ, ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³ , ìˆœì„œì— ë”°ë¼ ì˜¤ë¥˜ê°€ ëˆ„ì ë  ìˆ˜ ìˆìŒ (ì§‘í•©ì—ëŠ” ìˆœì„œë„ ì—†ë‹¤)
     â†’ ëª¨ë“  ê°ì²´ë¥¼ ë³‘ë ¬ë¡œ ì˜ˆì¸¡ (non-autoregressive)

---

## âš™ï¸ 3. DETR Architecture Overview

<img width="800" height="230" alt="image" src="https://github.com/user-attachments/assets/62676cba-f860-4735-9583-6db1e5408031" />


### ğŸ”¹ Backbone
<img width="448" height="154" alt="image" src="https://github.com/user-attachments/assets/8526a585-d969-4be2-9787-d2f5d10dd36b" /> <br>
- <img width="150" height="24" alt="image" src="https://github.com/user-attachments/assets/162ab421-f7cd-48b5-8356-6d383012f472" /> â†’ <img width="121" height="28" alt="image" src="https://github.com/user-attachments/assets/b0d5b00e-4f8d-4144-ae4a-9e79a31a4267" />
- C=2048, H, W = H0/32, W0/32
- ì´í›„ 1Ã—1 convë¡œ ì°¨ì› ì¶•ì†Œ (C â†’ d)

### ğŸ”¹ Transformer Encoder
- <img width="121" height="28" alt="image" src="https://github.com/user-attachments/assets/b0d5b00e-4f8d-4144-ae4a-9e79a31a4267" /> â†’ <img width="124" height="26" alt="image" src="https://github.com/user-attachments/assets/7ad54e83-3650-400e-93c8-002772ed8adc" />
- ì…ë ¥ featureë¥¼ flatten â†’ d x WH sequence  
- ê° ë ˆì´ì–´: **Multi-Head Self-Attention (MHSA) + FFN**
- **Fixed positional encoding** ì¶”ê°€ â†’ ìœ„ì¹˜ ì •ë³´ ë³´ì¡´
- ì—­í• : **instanceë¥¼ ë¶„ë¦¬(separate)**, ì´ë¯¸ì§€ ì „ì—­ ì •ë³´ í†µí•©

<img width="362" height="377" alt="image" src="https://github.com/user-attachments/assets/d13baae6-1464-49c1-b1c9-110b94542fd9" />


### ğŸ”¹ Transformer Decoder
- ìˆœì„œê°€ ìˆëŠ” sequence ê°€ ì•„ë‹Œ **ìˆœì„œê°€ ì—†ëŠ” ê°ì²´ ì§‘í•©(set) ì˜ˆì¸¡**
- ë•Œë¬¸ì— autoregressive ëŒ€ì‹  ë³‘ë ¬(parallel)ë¡œ Nê°œì˜ ê°ì²´ë¥¼ í•œë²ˆì— ì˜ˆì¸¡
- ì´ë•Œ decoderì˜ ì…ë ¥ : **object queries** <br>
  â†’ í•™ìŠµ ê°€ëŠ¥í•œ ë²¡í„°(learnable)ë¡œ, ê°ê°ì´ í•˜ë‚˜ì˜ ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” placeholder <br>
  â†’ decoderëŠ” permutation-invariant í•´ì•¼ í•˜ë¯€ë¡œ Nê°œì˜ embeddingì€ unique <br>
  â†’ **1 query = 1 detection slot**
  â†’ object queries = object query features(í•™ìŠµ ì‹œì‘ì‹œ 0ìœ¼ë¡œ ì´ˆê¸°í™”, learnable) + object query positional encoding(learnable)
- **Self-attention + Encoder-Decoder attention**
  - Self-attention: ê°ì²´ ê°„ ê´€ê³„ í•™ìŠµ  
  - Encoder-Decoder attention: ì´ë¯¸ì§€ì™€ì˜ ê´€ê³„ í•™ìŠµ

### ğŸ”¹ Feed-Forward Network (FFN)
- ê° ë””ì½”ë” ì¶œë ¥ â†’ 3-layer MLPë¡œ ë³€í™˜  
- ì¶œë ¥: `[bbox (cx, cy, h, w), class probability]`
- bboxëŠ” ì´ë¯¸ì§€ ëŒ€ë¹„ normalized
- **â€œno objectâ€ class** í¬í•¨ (ë¹ˆ ìŠ¬ë¡¯ ì²˜ë¦¬)

### ğŸ”¹ Auxiliary Decoding Losses
- ê° decoder layer í›„ì—ë„ FFN + Hungarian loss ì ìš©  
- â†’ í•™ìŠµ ì•ˆì •í™”, â€œì ì ˆí•œ ê°œìˆ˜ì˜ ê°ì²´ ì˜ˆì¸¡â€ì— ë„ì›€  
- ëª¨ë“  FFNì€ íŒŒë¼ë¯¸í„° ê³µìœ 

---

## ğŸ§© 4. Loss Function â€” Set Prediction Loss

### ì‚¬ì „ ì§€ì‹
#### â‘  Hungarian matching algorithm 
- ë‘ ì§‘í•© ì‚¬ì´ì˜ ì¼ëŒ€ì¼ ëŒ€ì‘ ì‹œ ê°€ì¥ ë¹„ìš©ì´ ì ê²Œ ë“œëŠ” bipartite matchint(ì´ë¶„ ë§¤ì¹­)ì„ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜
- ì–´ë–¤ ì§‘í•© Iì™€ matching ëŒ€ìƒì¸ ì§‘í•© Jê°€ ìˆìœ¼ë©° iâˆˆI ë¥¼ jâˆˆJì— ë§¤ì¹­í•˜ëŠ”ë° ë“œëŠ” ë¹„ìš©ì„ c(i,j)ë¼ê³  í•  ë•Œ, **Ïƒ:Iâ†’Jë¡œì˜ ì¼ëŒ€ì¼ ëŒ€ì‘ ì¤‘ì—ì„œ ê°€ì¥ ì ì€ costê°€ ë“œëŠ” matchingì— ëŒ€í•œ permutation Ïƒì„ ì°¾ëŠ” ê²ƒ**
<img width="728" height="285" alt="image" src="https://github.com/user-attachments/assets/b76759d0-193a-442e-99b8-c8baa67dd4f7" />
<img width="730" height="279" alt="image" src="https://github.com/user-attachments/assets/8cdabd12-c8f8-4d35-ab81-6cc89daa6562" />

#### â‘¡ Bounding box loss
- ê¸°ì¡´ì˜ detectorë“¤ì€ anchor ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ bbox ë²”ìœ„ê°€ í¬ê²Œ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ë‹¤
- DETRì€ initial guess ì—†ì´ ì˜ˆì¸¡í•˜ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ ê°’ì˜ ë²”ì£¼ê°€ í¬ë‹¤
- **scale-invariant** í•œ GIoU ë¥¼ L1 lossì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ë³´ì™„
<img width="500" height="375" alt="image" src="https://github.com/user-attachments/assets/6f51738a-a708-4042-8c96-061084f7a61a" />
<img width="323" height="88" alt="image" src="https://github.com/user-attachments/assets/adf9fc48-98ea-43b6-a0c6-1ebbe094350f" />



### â‘  Matching cost (Hungarian matching)
- ì˜ˆì¸¡ê³¼ ì •ë‹µ ê°„ **pairwise cost** ê³„ì‚°<br>
  cost = class_cost + giou_cost + bbox_l1_cost
- <img width="392" height="42" alt="image" src="https://github.com/user-attachments/assets/3b32352f-1b38-47ea-9580-f0790c6fe14a" />
- â€œno-object(âˆ…)â€ ë§¤ì¹­ì€ ìƒìˆ˜ cost  

### â‘¡ Loss êµ¬ì„±
- ì•ì˜ hungarian matchingìœ¼ë¡œ êµ¬í•œ pairë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
- <img width="488" height="42" alt="image" src="https://github.com/user-attachments/assets/8681c8eb-cec0-4819-be8c-1a0be6fdd288" />
- **Class term** : negative log-likelihood  
- **Box term** : L1 + GIoU (scale invariance ë³´ì™„)
- **no-object í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ 1/10** (class imbalance ì™„í™”)

---

## ğŸ§± 5. Training Details

- Optimizer: **AdamW**
  - Transformer lr = 1e-4  
  - Backbone lr = 1e-5  
  - weight decay = 1e-4
- Data Augmentation  
  - Image resize (shortest side 480 ~ 800)  
  - Random crop p=0.5  
  - Dropout 0.1  
- 300 epochs (200 + lr drop Ã— 0.1)
- Dataset: **COCO**

---

## ğŸ” 6. Results & Analysis

### âœ… ì„±ëŠ¥
- **Faster R-CNN** ìˆ˜ì¤€ì˜ ì„±ëŠ¥ (COCO AP â‰ˆ 42)  
- **í° ê°ì²´(large object)** ì—ì„œ íŠ¹íˆ ìš°ìˆ˜  
  - ì´ìœ : **Transformerì˜ non-local computation**  
    â†’ ì´ë¯¸ì§€ ì „ì—­ì˜ featureë¥¼ í•œ ë²ˆì— í†µí•©

### âš ï¸ í•œê³„
- í•™ìŠµ ì†ë„ê°€ ë§¤ìš° ëŠë¦¼ (300 epochs í•„ìš”)  
- ì‘ì€ ê°ì²´(small object)ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì„±ëŠ¥ í•˜ë½

---

## ğŸ”¬ 7. Ablation Study

| êµ¬ì„±ìš”ì†Œ | ì œê±° ì‹œ ì˜í–¥ | ì˜ë¯¸ |
|-----------|---------------|-------|
| **Encoder ì œê±°** | instance êµ¬ë¶„ ì‹¤íŒ¨, APâ†“ | ì „ì—­ self-attentionì´ ê°ì²´ ë¶„ë¦¬ì— ì¤‘ìš” |
| **Decoder ì œê±°** | local patchë§Œ ê³ ë ¤, APâ†“ | ì „ì—­ reasoning ì†ì‹¤ |
| **Positional Encoding ì œê±°** | ì•½ 7â€“8 AP í•˜ë½ | ê³µê°„ ì •ë³´ ì†ì‹¤ |
| **FFN ì œê±°** | ì•½ 2â€“3 AP í•˜ë½ | class + box ì˜ˆì¸¡ í’ˆì§ˆ ì €í•˜ |
| **Auxiliary Loss ì œê±°** | í•™ìŠµ ë¶ˆì•ˆì •, ìˆ˜ë ´ ëŠë¦¼ | ê° ë””ì½”ë” ë‹¨ê³„ì˜ ë³´ì¡° supervision í•„ìš” |

ğŸ“ˆ **ê²°ë¡ :**  
ê° êµ¬ì„±ìš”ì†Œê°€ ëª¨ë‘ ì„±ëŠ¥ì— í•„ìˆ˜ì ì´ë©°,  
íŠ¹íˆ **Transformerì˜ ì „ì—­ ì—°ì‚° + object query êµ¬ì¡°** ê°€ í•µì‹¬.

---

## ğŸ§  8. Key Takeaways

- DETRì€ **anchor, NMS, proposal ë“± ìˆ˜ì‘ì—… ê·œì¹™ì„ ëª¨ë‘ ì œê±°**  
- **Transformerì˜ self-attention** ìœ¼ë¡œ ê°ì²´ ê°„ ê´€ê³„ë¥¼ í•™ìŠµ  
- **Hungarian matching loss** ë¡œ 1:1 ë§¤ì¹­ + permutation invariance í™•ë³´  
- **ë³‘ë ¬ ë””ì½”ë”© (parallel decoding)** ìœ¼ë¡œ ëª¨ë“  ê°ì²´ë¥¼ ë™ì‹œì— ì˜ˆì¸¡  
- ì™„ì „í•œ **End-to-End object detection pipeline** ë‹¬ì„±  

---

## ğŸ§­ 9. Discussion

| ì¥ì  | ë‹¨ì  |
|------|------|
| âœ” ë‹¨ìˆœí•œ êµ¬ì¡° (anchor/NMS X) | âŒ ê¸´ í•™ìŠµ ì‹œê°„ |
| âœ” ê°ì²´ ê°„ ê´€ê³„ í•™ìŠµ | âŒ ì‘ì€ ê°ì²´ íƒì§€ ì•½í•¨ |
| âœ” ì „ì—­ ë¬¸ë§¥ í™œìš© | âŒ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œ ê³„ì‚°ëŸ‰ ë§ìŒ |

---

## ğŸ”® 10. Conclusion

> DETRì€ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì´ìš©í•´ ê°ì²´ ê²€ì¶œì„  
> **â€˜ìˆœì„œ ì—†ëŠ” ì§‘í•© ì˜ˆì¸¡(set prediction)â€™** ë¬¸ì œë¡œ ì¬ì •ì˜í•˜ì˜€ë‹¤.  
>  
> self-attentionìœ¼ë¡œ ê°ì²´ ê°„ ê´€ê³„ë¥¼ í•™ìŠµí•˜ê³ ,  
> í—ê°€ë¦¬ì•ˆ ë§¤ì¹­ì„ í†µí•´ ì¤‘ë³µ ì—†ëŠ” ì˜ˆì¸¡ì„ ë‹¬ì„±í•˜ì—¬  
> ê°ì²´ ê²€ì¶œì„ **ì§„ì •í•œ End-to-End í•™ìŠµ ë¬¸ì œ**ë¡œ ë°”ê¿”ë†“ì•˜ë‹¤.

---

### ğŸ“š Reference
- Carion et al., â€œEnd-to-End Object Detection with Transformers,â€ ECCV 2020.
